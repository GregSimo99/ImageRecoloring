{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Recoloring\n",
        "**TODO:**\n",
        "\n",
        "\n",
        "* Dataset class\n",
        "* Training and test split\n",
        "* Data augmentation (?)\n",
        "* Model of generator and discriminator\n",
        "* Loss function\n",
        "* Traing procedure\n",
        "\n"
      ],
      "metadata": {
        "id": "exzWdD-hiKTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PRh1JRuj9QJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "57vhPwr8mGNw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset\n",
        "\n",
        "The dataset is shared here https://drive.google.com/file/d/1Zq46n_VFuENm1OLaRaKQkIqq8wA__vFq/view?usp=sharing. Add a shortcut to your own google drive and mount drive on google colab."
      ],
      "metadata": {
        "id": "nLZ3lWLL90fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l-W6UK1T96aV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8084500d-bda8-43d8-faf0-321ce95d86d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/COCOtrain2014.zip\n",
        "!rm -rf /content/__MACOSX"
      ],
      "metadata": {
        "id": "zy65hp9bnboT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALby:\n",
        "\n",
        "\n",
        "*   Classe dataset e dataloader\n",
        "*   Resize a 256 x 256\n",
        "* Bianco e nero \n",
        "* split train e test (80:20)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a23CvQSS1a9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the models"
      ],
      "metadata": {
        "id": "qHfLMmIQ-INO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator"
      ],
      "metadata": {
        "id": "ft3php1X_AxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.down1 = Block(64, 128, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(128, 256, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down3 = Block(256, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down4 = Block(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down5 = Block(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down6 = Block(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # U-Net decoder model: CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
        "        self.up1 = Block(512, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = Block(1024, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up3 = Block(1024, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up4 = Block(1024, 512, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up5 = Block(1024, 256, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up6 = Block(512, 128, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up7 = Block(256, 64, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        return self.final_up(torch.cat([up7, d1], 1))\n",
        "\n",
        "def test():\n",
        "    x = torch.randn((1, 3, 256, 256))\n",
        "    model = Generator(in_channels=3)\n",
        "    preds = model(x)\n",
        "    print(model)\n",
        "    print(preds.shape)"
      ],
      "metadata": {
        "id": "u2s9N_nJ_E0c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "id": "Q6mkQx0Nf25B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "The architecture for the PatchGAN Discriminator (70x70 patch) is:\n",
        " \n",
        "\n",
        "1.   Convolutional layer with 64 filters, kernel size=4, stride=2, padding=1, LeakyRelu (with negative_slope=0.2)\n",
        "2.   Convolutional layer with 128 filters, kernel size=4 stride=2, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n",
        "3.   Convolutional layer with 256 filters, kernel size=4 stride=2, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n",
        "4.   Convolutional layer with 512 filters, kernel size=4 stride=1, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n"
      ],
      "metadata": {
        "id": "I74D5aXe_GKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlockBN(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s=2):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride=s, padding=1, bias=False, padding_mode=\"reflect\"),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "# CNN without Batch Normalization\n",
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s=2):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride=s, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    features = [64, 128, 256, 512]\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        CNNBlock(3*2, features[0]),    #*2 two image concatenated \n",
        "        CNNBlockBN(features[0], features[1]),\n",
        "        CNNBlockBN(features[1], features[2]),\n",
        "        # last block with stride = 1\n",
        "        CNNBlockBN(features[2], features[3], s=1),\n",
        "        nn.Conv2d(features[3], 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\")\n",
        "    )\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat([x, y], dim=1)\n",
        "    x = self.model(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NKkjtlm8_NO_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model \n",
        "def test():\n",
        "  # 1 image with 3 channels 256x256\n",
        "  x = torch.randn((1, 3, 256, 256))\n",
        "  y = torch.randn((1, 3, 256, 256))\n",
        "  model = Discriminator()\n",
        "  preds = model(x, y)\n",
        "  print(model)\n",
        "  print(preds.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "e3QrS4l1J1J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weights initialization"
      ],
      "metadata": {
        "id": "nXD_Fx1XlT_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model, init=\"normal\"):\n",
        "    classname = model.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1:\n",
        "        if(init==\"xavier\"): \n",
        "          nn.init.xavier_uniform_(model.weight.data)\n",
        "        if(init==\"normal\"):\n",
        "          nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.2)\n",
        "        nn.init.constant_(model.bias.data, 0)"
      ],
      "metadata": {
        "id": "mfarZbuElXvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "H4jqh3PmWmry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train loop"
      ],
      "metadata": {
        "id": "arLqPx3Xd1jR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper parameters (see paper)"
      ],
      "metadata": {
        "id": "YT2_wux9eYGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L1_LAMBDA = 100\n",
        "NUM_EPOCHS= 100\n",
        "BATCH_SIZE = 1    # sul video è 16; paper è 4 (o da 1 a 10)\n",
        "LR=0.0002 \n",
        "BETA1=0.5\n",
        "BETA2=0.999\n",
        "LOAD_MODEL = False\n",
        "CHECKPOINT_GEN = \"disc.pth.tar\"\n",
        "CHECKPOINT_DISC = \"gen.pth.tar\""
      ],
      "metadata": {
        "id": "6t3pTUIAdfM3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('GPU availble')\n",
        "  # Define the device (here you can select which GPU to use if more than 1)\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print('GPU not availble')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "JSlLbV6NY9Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop():\n",
        "    disc = Discriminator()\n",
        "    gen = Generator(in_channels=3)\n",
        "    if not LOAD_MODEL:\n",
        "      disc.apply(initialize_weights)\n",
        "      gen.apply(initialize_weights)\n",
        "    disc.to(device)\n",
        "    gen.to(device)\n",
        "\n",
        "    opt_disc = optim.Adam(disc.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "    BCE = nn.BCEWithLogitsLoss()\n",
        "    L1_LOSS = nn.L1Loss()\n",
        "\n",
        "    # Load the model \n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(CHECKPOINT_GEN, gen, opt_gen, LR)\n",
        "        load_checkpoint(CHECKPOINT_DISC, disc, opt_disc, LR)\n",
        "\n",
        "    #train_dataset = MapDataset(root_dir=config.TRAIN_DIR)     # classe di ALBY\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=os.cpu_count(),\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "    #val_dataset = MapDataset(root_dir=config.VAL_DIR)     # classe di ALBY\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        training_step(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler)\n",
        "\n",
        "        # Save weights\n",
        "        if epoch % 5 == 0:\n",
        "          save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
        "          save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n",
        "\n",
        "\n",
        "        #show_some_examples()\n"
      ],
      "metadata": {
        "id": "iZEIw4lyWp-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (x, y) in enumerate(loop):\n",
        "        x = x.to(device)    # BW image\n",
        "        y = y.to(device)    # original image\n",
        "\n",
        "        # Train Discriminator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            y_fake = gen(x)\n",
        "            D_real = disc(x, y)\n",
        "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "            D_fake = disc(x, y_fake.detach())\n",
        "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "\n",
        "        disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_fake = disc(x, y_fake)\n",
        "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
        "            G_loss = G_fake_loss + L1\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        # To show the loss\n",
        "        if idx % 10 == 0:\n",
        "            loop.set_postfix(\n",
        "                D_real=torch.sigmoid(D_real).mean().item(),\n",
        "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
        "            )\n"
      ],
      "metadata": {
        "id": "We9vtfUEkMGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utility functions"
      ],
      "metadata": {
        "id": "FuM7__Yoc2IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)"
      ],
      "metadata": {
        "id": "mzM-X091c5_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "d9vivy7SdUC_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_some_examples(gen, val_loader, epoch, folder):\n",
        "  #TODO\n",
        "  x, y = next(iter(val_loader))\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  gen.eval()\n",
        "  with torch.no_grad():\n",
        "    '''\n",
        "    y_fake = gen(x)\n",
        "    y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
        "    save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "    save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
        "    if epoch == 1:\n",
        "      save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "    '''\n",
        "  gen.train()\n"
      ],
      "metadata": {
        "id": "nFCt5KYqgBBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}