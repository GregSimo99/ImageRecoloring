{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Recoloring\n",
        "**TODO:**\n",
        "\n",
        "\n",
        "* Dataset class\n",
        "* Training and test split\n",
        "* Data augmentation (?)\n",
        "* Model of generator and discriminator\n",
        "* Loss function\n",
        "* Traing procedure\n",
        "\n"
      ],
      "metadata": {
        "id": "exzWdD-hiKTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PRh1JRuj9QJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "57vhPwr8mGNw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import time as time\n",
        "import numpy as np\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset\n",
        "\n",
        "The dataset is shared here https://drive.google.com/file/d/1Zq46n_VFuENm1OLaRaKQkIqq8wA__vFq/view?usp=sharing. Add a shortcut to your own google drive and mount drive on google colab."
      ],
      "metadata": {
        "id": "nLZ3lWLL90fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l-W6UK1T96aV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8084500d-bda8-43d8-faf0-321ce95d86d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/COCOtrain2014.zip\n",
        "!rm -rf /content/__MACOSX"
      ],
      "metadata": {
        "id": "zy65hp9bnboT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALby:\n",
        "\n",
        "\n",
        "*   Classe dataset e dataloader\n",
        "*   Resize a 256 x 256\n",
        "* Bianco e nero \n",
        "* split train e test (80:20)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a23CvQSS1a9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the models"
      ],
      "metadata": {
        "id": "qHfLMmIQ-INO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator"
      ],
      "metadata": {
        "id": "ft3php1X_AxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.down1 = Block(64, 128, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(128, 256, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down3 = Block(256, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down4 = Block(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down5 = Block(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down6 = Block(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # decoder model: CD512-CD512-CD512-C512-C256-C128-C64\n",
        "        self.up1 = Block(512, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = Block(1024, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up3 = Block(1024, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up4 = Block(1024, 512, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up5 = Block(1024, 256, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up6 = Block(512, 128, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up7 = Block(256, 64, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        return self.final_up(torch.cat([up7, d1], 1))\n",
        "\n",
        "def test():\n",
        "    x = torch.randn((1, 3, 256, 256))\n",
        "    model = Generator(in_channels=3)\n",
        "    preds = model(x)\n",
        "    print(preds.shape)"
      ],
      "metadata": {
        "id": "u2s9N_nJ_E0c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "The architecture for the PatchGAN Discriminator (70x70 patch) is:\n",
        " \n",
        "\n",
        "1.   Convolutional layer with 64 filters, kernel size=4, stride=2, padding=1, LeakyRelu (with negative_slope=0.2)\n",
        "2.   Convolutional layer with 128 filters, kernel size=4 stride=2, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n",
        "3.   Convolutional layer with 256 filters, kernel size=4 stride=2, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n",
        "4.   Convolutional layer with 512 filters, kernel size=4 stride=1, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n"
      ],
      "metadata": {
        "id": "I74D5aXe_GKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlockBN(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s=2):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride=s, bias=False, padding_mode=\"reflect\"),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "# CNN without Batch Normalization\n",
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s=2):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride=s, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    features = [64, 128, 256, 512]\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        CNNBlock(3*2, features[0]),    #*2 two image concatenated \n",
        "        CNNBlockBN(features[0], features[1]),\n",
        "        CNNBlockBN(features[1], features[2]),\n",
        "        # last block with stride = 1\n",
        "        CNNBlockBN(features[2], features[3], s=1),\n",
        "        nn.Conv2d(features[3], 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\")\n",
        "    )\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat([x, y], dim=1)\n",
        "    x = self.model(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NKkjtlm8_NO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model \n",
        "\n",
        "def test():\n",
        "  # 1 image with 3 channels 256x256\n",
        "  x = torch.randn((1, 3, 256, 256))\n",
        "  y = torch.randn((1, 3, 256, 256))\n",
        "  model = Discriminator()\n",
        "  preds = model(x, y)\n",
        "  print(model)\n",
        "  print(preds.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3QrS4l1J1J_",
        "outputId": "8b085ff3-6dbf-4baa-c8ef-e36819f63570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): CNNBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (1): CNNBlockBN(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), bias=False, padding_mode=reflect)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (2): CNNBlockBN(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), bias=False, padding_mode=reflect)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (3): CNNBlockBN(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), bias=False, padding_mode=reflect)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "  )\n",
            ")\n",
            "torch.Size([1, 1, 26, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the loss"
      ],
      "metadata": {
        "id": "QUN0i7CsCRqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator loss"
      ],
      "metadata": {
        "id": "VHU5VNizCVfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# codice"
      ],
      "metadata": {
        "id": "F_m6q9cZCZKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator loss"
      ],
      "metadata": {
        "id": "N67IJw9dCkl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# codice"
      ],
      "metadata": {
        "id": "-iE0LHNRCo07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "H4jqh3PmWmry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# codice"
      ],
      "metadata": {
        "id": "iZEIw4lyWp-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}