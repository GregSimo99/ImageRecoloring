{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzWdD-hiKTe"
      },
      "source": [
        "# Image Recoloring\n",
        "**TODO:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRh1JRuj9QJr"
      },
      "source": [
        "## Setup\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "57vhPwr8mGNw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "from numpy import arange\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt                      \n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.models import VGG16_Weights\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from fastai.data.external import untar_data,URLs\n",
        "from fastai.data.transforms import get_image_files\n",
        "\n",
        "import PIL\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import cv2\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "!pip install fastai==2.4\n",
        "from fastai.vision.learner import create_body\n",
        "from torchvision.models.resnet import resnet18\n",
        "from fastai.vision.models.unet import DynamicUnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLZ3lWLL90fZ"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "The dataset is shared here https://drive.google.com/file/d/1PKDBVy1rmymKTKLTlB6iLQI1GLXcEpl0/view?usp=sharing. Add a shortcut to your own google drive and mount drive on google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-W6UK1T96aV",
        "outputId": "215a1a84-d5e6-418b-9007-86fb08594c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy65hp9bnboT"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/COCOdataset.zip\n",
        "!rm -rf /content/__MACOSX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3A1d0FL8TFq"
      },
      "outputs": [],
      "source": [
        "# to see if the dataset is working correctly\n",
        "coco_path = '/content/val2014'\n",
        "dataset = get_image_files(coco_path)   \n",
        "img = PIL.Image.open(dataset[1])\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hVX2SL__PW0j",
        "outputId": "0e5a7a03-ed72-49f7-9c3f-2cd079834bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length:  40504\n",
            "Images dimensions:  (640, 428)\n"
          ]
        }
      ],
      "source": [
        "# basic info of the dataset\n",
        "print(\"Dataset length: \", len(dataset))\n",
        "print(\"Images dimensions: \", img.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bAFqknZU62tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477fb269-12f2-465c-c6c5-82df349a4f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 5000\n",
            "Test set length: 1000\n",
            "Validation set length: 1000\n"
          ]
        }
      ],
      "source": [
        "paths_list = glob.glob(coco_path+\"/*.jpg\")                              # paths_list is a list with all the image files names of our dataset\n",
        "np.random.seed(123)                                                     # Seeding for reproducible results\n",
        "paths_subset = np.random.choice(paths_list, 35000, replace=False)       # Randomly choosing 35000 images from the list\n",
        "rand_indexes = np.random.permutation(35000)                             # Shuffling the indexes\n",
        "train_indexes = rand_indexes[:25000]                                    # Using 25000 images for training\n",
        "val_indexes = rand_indexes[25000:30000]                                 # Using 5000 images for validation\n",
        "test_indexes = rand_indexes[30000:31000]                                # Using 1000 images for testing\n",
        "train_paths = paths_subset[train_indexes]                               # Array with all the image files names for the training\n",
        "test_paths = paths_subset[test_indexes]                                 # Array with all the image files names for the test\n",
        "val_paths = paths_subset[val_indexes]                                   # Array with all the image files names for the validation\n",
        "\n",
        "print(\"Training set length: \"+str(len(train_paths)))\n",
        "print(\"Test set length: \"+str(len(test_paths)))\n",
        "print(\"Validation set length: \"+str(len(val_paths)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFZyiPkT31Yk"
      },
      "source": [
        "## Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qNFixNU17VBo"
      },
      "outputs": [],
      "source": [
        "SIZE = 256   # fixed size of the images \n",
        "\n",
        "class image_coloring_dataset(Dataset):\n",
        "    def __init__(self, paths, split='train'):\n",
        "        if split == 'train':\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
        "                # Data augmentation\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),\n",
        "            ])\n",
        "        elif split == 'test':\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
        "            \n",
        "        elif split == 'val':\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
        "        \n",
        "        self.split = split\n",
        "        self.size = SIZE\n",
        "        self.paths = paths\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "        img = np.array(img)\n",
        "        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n",
        "        img_lab = transforms.ToTensor()(img_lab)\n",
        "        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n",
        "        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
        "        \n",
        "        return L, ab     #{'L': L, 'ab': ab}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHfLMmIQ-INO"
      },
      "source": [
        "## Create the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft3php1X_AxZ"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetGenerator(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=2, size=256):\n",
        "        super(ResNetGenerator, self).__init__()\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = resnet18()  # Instantiate the resnet18 model\n",
        "        body = create_body(model, pretrained=True, n_in=n_input, cut=-2)\n",
        "        self.net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net_G(x)\n",
        "\n",
        "# Create an instance of the ResNetGenerator class\n",
        "net_G = ResNetGenerator(n_input=1, n_output=2, size=256)"
      ],
      "metadata": {
        "id": "3WuglhKbvvXp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I74D5aXe_GKJ"
      },
      "source": [
        "### Discriminator\n",
        "The architecture for the PatchGAN Discriminator (70x70 patch) is:\n",
        " \n",
        "\n",
        "1.   Convolutional layer with 64 filters, kernel size=4, stride=2, padding=1, LeakyRelu (with negative_slope=0.2)\n",
        "2.   Convolutional layer with 128 filters, kernel size=4 stride=2, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n",
        "3.   Convolutional layer with 256 filters, kernel size=4 stride=2, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n",
        "4.   Convolutional layer with 512 filters, kernel size=4 stride=1, padding=1, LeakyRelu (with negative_slope=0.2) and with Batch Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NKkjtlm8_NO_"
      },
      "outputs": [],
      "source": [
        "class CNNBlockBN(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s=2):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride=s, padding=1, bias=False, padding_mode=\"reflect\"),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "# CNN without Batch Normalization\n",
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s=2):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride=s, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    features = [64, 128, 256, 512]\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        CNNBlock(in_channels, features[0]),\n",
        "        CNNBlockBN(features[0], features[1]),\n",
        "        CNNBlockBN(features[1], features[2]),\n",
        "        # last block with stride = 1\n",
        "        CNNBlockBN(features[2], features[3], s=1),\n",
        "        nn.Conv2d(features[3], 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\")\n",
        "    )\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat([x, y], dim=1)\n",
        "    x = self.model(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3QrS4l1J1J_"
      },
      "outputs": [],
      "source": [
        "# test the model \n",
        "def test():\n",
        "  # 1 image with 1 channels 256x256\n",
        "  x = torch.randn((1, 1, 256, 256))\n",
        "  # 1 image with 2 channels 256x256\n",
        "  y = torch.randn((1, 2, 256, 256))\n",
        "  model = Discriminator(in_channels = 3)\n",
        "  preds = model(x, y)\n",
        "  print(model)\n",
        "  print(preds.shape)\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXD_Fx1XlT_i"
      },
      "source": [
        "Weights initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mfarZbuElXvF"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(model, init=\"normal\"):\n",
        "    classname = model.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1:\n",
        "        if(init==\"xavier\"): \n",
        "          nn.init.xavier_uniform_(model.weight.data)\n",
        "        if(init==\"normal\"):\n",
        "          nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.2)\n",
        "        nn.init.constant_(model.bias.data, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4jqh3PmWmry"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuM7__Yoc2IR"
      },
      "source": [
        "###Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mzM-X091c5_t"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, filename):\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d9vivy7SdUC_"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nFCt5KYqgBBd"
      },
      "outputs": [],
      "source": [
        "def labToRGB(L, ab):\n",
        "  L = (L + 1.) * 50.\n",
        "  ab = ab * 110.\n",
        "  Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "  rgb_imgs = []\n",
        "  for img in Lab:\n",
        "    img_rgb = lab2rgb(img)\n",
        "    rgb_imgs.append(img_rgb)\n",
        "  return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def show_some_examples(gen, disc, l1, bce, val_loader):\n",
        "  D_loss_values = []\n",
        "  G_loss_values = []\n",
        "  Total_gel_loss_values = []\n",
        "  L1_loss_values = []\n",
        "  D_fake_values = []\n",
        "  D_real_values = []\n",
        "  # TODO: elimina quello sbagliato\n",
        "  D_real_sig_values = []\n",
        "  D_fake_sig_values = []\n",
        "  D_loss_sig_values = []\n",
        "\n",
        "  x, y = next(iter(val_loader))\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  #print(\"Shape of x: \", x.shape)\n",
        "  #print(\"Shape of y: \", y.shape)\n",
        "  # obtain original RGB image\n",
        "  real_imgs = labToRGB(x, y)\n",
        "  gen.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    y_fake = gen(x)\n",
        "    # compute the losses\n",
        "    # Discriminator\n",
        "    D_real = disc(x, y)\n",
        "    D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "    D_fake = disc(x, y_fake.detach())\n",
        "    D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "    # TODO: cancella quello sbagliato\n",
        "    D_loss_sig_values.append(torch.sigmoid(D_fake).mean().item() + torch.sigmoid(D_real).mean().item())\n",
        "    D_fake_sig_values.append(torch.sigmoid(D_fake).mean().item())\n",
        "    D_real_sig_values.append(torch.sigmoid(D_real).mean().item())\n",
        "\n",
        "    D_real_values.append(D_real_loss.item())\n",
        "    D_fake_values.append(D_fake_loss.item())\n",
        "    D_loss_values.append(D_loss.item())\n",
        "    \n",
        "    # Generator\n",
        "    D_fake = disc(x, y_fake)\n",
        "    G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "    L1 = l1(y_fake, y) * L1_LAMBDA\n",
        "    G_loss = G_fake_loss + L1\n",
        "\n",
        "    G_loss_values.append(G_fake_loss.item())\n",
        "    L1_loss_values.append(L1.item())\n",
        "    Total_gel_loss_values.append(G_loss.item())\n",
        "\n",
        "  rgbImgs = labToRGB(x, y_fake)\n",
        "  bsize = val_loader.batch_size\n",
        "  # Set the size of the plot\n",
        "  fig = plt.figure(figsize=(15, 8))\n",
        "  for i in range(bsize):\n",
        "    ax = plt.subplot(3, bsize, i + 1)\n",
        "    ax.imshow(x[i][0].cpu(), cmap='gray')\n",
        "    ax.axis(\"off\")\n",
        "    ax = plt.subplot(3, bsize, i + 1 + bsize)\n",
        "    ax.imshow(rgbImgs[i])\n",
        "    ax.axis(\"off\")\n",
        "    ax = plt.subplot(3, bsize, i + 1 + bsize*2)\n",
        "    ax.imshow(real_imgs[i])\n",
        "    ax.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "  gen.train()\n",
        "  # TODO: cancella quello sbagliato\n",
        "  return {'Gen_loss': np.mean(G_loss_values),\n",
        "            'Total_gen_loss' : np.mean(Total_gel_loss_values), \n",
        "            'L1_loss' : np.mean(L1_loss_values),\n",
        "            'Disc_loss' : np.mean(D_loss_values),\n",
        "            'D_fake' : np.mean(D_fake_values),\n",
        "            'D_real' : np.mean(D_real_values),\n",
        "            'Disc_loss_sig' : np.mean(D_loss_sig_values),\n",
        "            'D_fake_sig' : np.mean(D_fake_sig_values),\n",
        "            'D_real_sig' : np.mean(D_real_sig_values)\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT2_wux9eYGp"
      },
      "source": [
        "\n",
        "###Hyper parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODEL = True\n",
        "SAVE_MODEL = True\n",
        "TEST = False"
      ],
      "metadata": {
        "id": "vj4RXu2GP2xq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6t3pTUIAdfM3"
      },
      "outputs": [],
      "source": [
        "L1_LAMBDA = 100\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 16    # sul video è 16; paper è 4 (o da 1 a 10)\n",
        "LR = 0.0002 \n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.999\n",
        "CHECKPOINT_DISC = \"/content/drive/MyDrive/weights_GAN/RESNETdisc.pth.tar\"\n",
        "CHECKPOINT_GEN = \"/content/drive/MyDrive/weights_GAN/RESNETgen.pth.tar\"\n",
        "TRAIN_LOSSES = \"/content/drive/MyDrive/weights_GAN/RESNETloss_train_data.pkl\"\n",
        "VAL_LOSSES = \"/content/drive/MyDrive/weights_GAN/RESNETloss_val_data.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JSlLbV6NY9Sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a73990-1b18-4662-df83-caf566f2211b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU availble\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('GPU availble')\n",
        "  # Define the device (here you can select which GPU to use if more than 1)\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print('GPU not availble')\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLqPx3Xd1jR"
      },
      "source": [
        "###Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iZEIw4lyWp-V"
      },
      "outputs": [],
      "source": [
        "def train_loop():\n",
        "    # Track losses\n",
        "    # TODO: cancella chiavi sbagliate\n",
        "    history = {'Gen_loss' : [], 'Total_gen_loss' : [], 'L1_loss' : [], 'Disc_loss' : [], 'D_fake': [], 'D_real' : [], 'Disc_loss_sig' : [], 'D_fake_sig': [], 'D_real_sig' : []}\n",
        "    history_val = {'Gen_loss' : [], 'Total_gen_loss' : [], 'L1_loss' : [], 'Disc_loss' : [], 'D_fake': [], 'D_real' : [], 'Disc_loss_sig' : [], 'D_fake_sig': [], 'D_real_sig' : []}\n",
        "    # recover previous history\n",
        "    try:\n",
        "      history = pickle.load(open(TRAIN_LOSSES, 'rb'))\n",
        "      history_val = pickle.load(open(VAL_LOSSES, 'rb'))\n",
        "      # recover the number of epochs completed \n",
        "      e_completed = len(history['Gen_loss'])\n",
        "      print(\"Number of epochs previously done: \", e_completed)\n",
        "    except FileNotFoundError:\n",
        "      e_completed = 0\n",
        "      print(\"File of previous history not found\")\n",
        "    \n",
        "    disc = Discriminator(in_channels = 3)\n",
        "    gen = net_G                                           \n",
        "    if not LOAD_MODEL:\n",
        "      print('Initializing the weights...')\n",
        "      disc.apply(initialize_weights)\n",
        "      gen.apply(initialize_weights)\n",
        "    disc.to(device)\n",
        "    gen.to(device)\n",
        "\n",
        "    # Optimizers definition \n",
        "    opt_disc = optim.Adam(disc.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "    # Losses definition\n",
        "    BCE = nn.BCEWithLogitsLoss()\n",
        "    L1_LOSS = nn.L1Loss()\n",
        "\n",
        "    # Load the model \n",
        "    if LOAD_MODEL:\n",
        "        print('Loading the model from the last checkpoint...')\n",
        "        print(\"=> Loading checkpoint for generator\")\n",
        "        load_checkpoint(CHECKPOINT_GEN, gen, opt_gen, LR)\n",
        "        print(\"=> Loading checkpoint for discriminator\")\n",
        "        load_checkpoint(CHECKPOINT_DISC, disc, opt_disc, LR)\n",
        "\n",
        "    # Load training set\n",
        "    train_dataset = image_coloring_dataset(paths=train_paths, split='train')\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=os.cpu_count(),\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "    # Load validation set \n",
        "    val_dataset = image_coloring_dataset(paths=test_paths, split='val')\n",
        "    val_loader = DataLoader(val_dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS - e_completed):\n",
        "        loss_dict = training_step(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler)\n",
        "\n",
        "        # Save the losses history\n",
        "        history['Gen_loss'].append(loss_dict['Gen_loss'])\n",
        "        history['Total_gen_loss'].append(loss_dict['Total_gen_loss'])\n",
        "        history['L1_loss'].append(loss_dict['L1_loss'])\n",
        "        history['Disc_loss'].append(loss_dict['Disc_loss'])\n",
        "        history['D_fake'].append(loss_dict['D_fake'])\n",
        "        history['D_real'].append(loss_dict['D_real'])\n",
        "        history['Disc_loss_sig'].append(loss_dict['Disc_loss_sig'])\n",
        "        history['D_fake_sig'].append(loss_dict['D_fake_sig'])\n",
        "        history['D_real_sig'].append(loss_dict['D_real_sig'])\n",
        "\n",
        "        # Save weights\n",
        "        # if epoch % 2 == 0 and epoch != 100 and epoch != 50:\n",
        "        if SAVE_MODEL:\n",
        "          print(\"=> Saving checkpoint for generator\")\n",
        "          save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
        "          print(\"=> Saving checkpoint for discriminator\")\n",
        "          save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n",
        "\n",
        "        print(\"Epoch completed: \", epoch+1+e_completed, \"/\", NUM_EPOCHS)\n",
        "        for loss_name, loss_value in loss_dict.items():\n",
        "          print(loss_name,\": \", loss_value)\n",
        "        print('\\n')\n",
        "\n",
        "        # Show some generated images for validation and compute the losses\n",
        "        loss_dict_val = show_some_examples(gen, disc, L1_LOSS, BCE, val_loader)\n",
        "        history_val['Gen_loss'].append(loss_dict_val['Gen_loss'])\n",
        "        history_val['Total_gen_loss'].append(loss_dict_val['Total_gen_loss'])\n",
        "        history_val['L1_loss'].append(loss_dict_val['L1_loss'])\n",
        "        history_val['Disc_loss'].append(loss_dict_val['Disc_loss'])\n",
        "        history_val['D_fake'].append(loss_dict_val['D_fake'])\n",
        "        history_val['D_real'].append(loss_dict_val['D_real'])\n",
        "        history_val['Disc_loss_sig'].append(loss_dict['Disc_loss_sig'])\n",
        "        history_val['D_fake_sig'].append(loss_dict['D_fake_sig'])\n",
        "        history_val['D_real_sig'].append(loss_dict['D_real_sig'])\n",
        "    \n",
        "        # save losses on files\n",
        "        with open(TRAIN_LOSSES, 'wb') as fp:\n",
        "          pickle.dump(history, fp)\n",
        "          print('Dictionary of loss train values saved successfully to file')\n",
        "\n",
        "        with open(VAL_LOSSES, 'wb') as fp:\n",
        "          pickle.dump(history_val, fp)\n",
        "          print('Dictionary of loss validation data saved successfully to file')\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "We9vtfUEkMGY"
      },
      "outputs": [],
      "source": [
        "def training_step(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    G_loss_values = []\n",
        "    G_loss_tot_values = []\n",
        "    L1_values = []\n",
        "    # TODO: elimina quello sbagliato\n",
        "    D_real_sig_values = []\n",
        "    D_fake_sig_values = []\n",
        "    D_loss_sig_values = []\n",
        "    D_real_values = []\n",
        "    D_fake_values = []\n",
        "    D_loss_values = []\n",
        "    \n",
        "    for idx, (x, y) in enumerate(loop):\n",
        "        x = x.to(device)    # BW image\n",
        "        y = y.to(device)    # original image\n",
        "\n",
        "        # Train Discriminator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            y_fake = gen(x)\n",
        "            D_real = disc(x, y)\n",
        "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "            D_fake = disc(x, y_fake.detach())\n",
        "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "            D_loss = D_real_loss + D_fake_loss\n",
        "            \n",
        "        # TODO: elimina quello sbagliato\n",
        "        D_real_sig_values.append(torch.sigmoid(D_real).mean().item())\n",
        "        D_fake_sig_values.append(torch.sigmoid(D_fake).mean().item())\n",
        "        D_loss_sig_values.append(torch.sigmoid(D_fake).mean().item() + torch.sigmoid(D_real).mean().item()) #D_loss.mean().item())\n",
        "        \n",
        "        D_real_values.append(D_real_loss.item())\n",
        "        D_fake_values.append(D_fake_loss.item())\n",
        "        D_loss_values.append(D_loss.item())\n",
        "\n",
        "        disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_fake = disc(x, y_fake)\n",
        "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
        "            G_loss = G_fake_loss + L1\n",
        "\n",
        "            G_loss_values.append(G_fake_loss.item())\n",
        "            L1_values.append(L1.item())\n",
        "            G_loss_tot_values.append(G_loss.item())\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        # Every 10 batchs show the loss\n",
        "        if idx % 10 == 0:\n",
        "            loop.set_postfix(\n",
        "                D_real=D_real_loss.item(),  #D_real=torch.sigmoid(D_real).mean().item(), \n",
        "                D_fake=D_fake_loss.item(),  #D_fake=torch.sigmoid(D_fake).mean().item(),\n",
        "                Gen_loss=G_fake_loss.item(),\n",
        "                Total_gen_loss=G_loss.item(),\n",
        "                Disc_loss=D_loss.item(),\n",
        "            )\n",
        "\n",
        "    # TODO: cancellare quello sbagliato\n",
        "    return {'Gen_loss': np.mean(G_loss_values),\n",
        "            'Total_gen_loss' : np.mean(G_loss_tot_values), \n",
        "            'L1_loss' : np.mean(L1_values),\n",
        "            'Disc_loss' : np.mean(D_loss_values),\n",
        "            'D_fake' : np.mean(D_fake_values),\n",
        "            'D_real' : np.mean(D_real_values),\n",
        "            'Disc_loss_sig' : np.mean(D_loss_sig_values),\n",
        "            'D_fake_sig' : np.mean(D_fake_sig_values),\n",
        "            'D_real_sig' : np.mean(D_real_sig_values)\n",
        "            }   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnvrUkXT_aLi"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7Avi5rH6gBs"
      },
      "outputs": [],
      "source": [
        "if not TEST:\n",
        "  train_loop()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot train and validation losses"
      ],
      "metadata": {
        "id": "U5b8583U_Dnc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-s5PyaJnJcW"
      },
      "outputs": [],
      "source": [
        "# Load the training and validation loss dictionaries\n",
        "train_losses = pickle.load(open(TRAIN_LOSSES, 'rb')) \n",
        "val_losses = pickle.load(open(VAL_LOSSES, 'rb'))\n",
        "G_loss = train_losses['Gen_loss']\n",
        "D_loss = train_losses['Disc_loss']\n",
        "D_fake = train_losses['D_fake']\n",
        "D_real = train_losses['D_real']\n",
        "Total_gen_loss = train_losses['Total_gen_loss']\n",
        "L1_loss = train_losses['L1_loss']\n",
        "\n",
        "G_loss_val = val_losses['Gen_loss']\n",
        "D_loss_val = val_losses['Disc_loss']\n",
        "D_fake_val = val_losses['D_fake']\n",
        "D_real_val = val_losses['D_real']\n",
        "Total_gen_loss_val = val_losses['Total_gen_loss']\n",
        "L1_loss_val = val_losses['L1_loss']\n",
        "\n",
        "def plot_train_val_loss(n_epochs, train_values, val_values, title):\n",
        "  epochs = range(1, n_epochs+1)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(epochs, train_values, label='Training Loss')\n",
        "  plt.plot(epochs, val_values, label='Validation Loss')\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  # Set the tick locations\n",
        "  plt.xticks(arange(1, n_epochs+1, 3))\n",
        "  # Display the plot\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "def plot_gen_disc_loss(n_epochs, gen_values, disc_values, title):\n",
        "  epochs = range(1, n_epochs+1)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(epochs, gen_values, label='Generator Loss')\n",
        "  plt.plot(epochs, disc_values, label='Discriminator Loss')\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  # Set the tick locations\n",
        "  plt.xticks(arange(1, n_epochs+1, 1))\n",
        "  # Display the plot\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss(n_epochs, loss_values, title, label):\n",
        "  epochs = range(1, n_epochs+1)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(epochs, loss_values, label=label)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  # Set the tick locations\n",
        "  plt.xticks(arange(1, n_epochs+1, 1))\n",
        "  # Display the plot\n",
        "  #plt.legend(loc='best')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Epochs done so far: \", len(G_loss))"
      ],
      "metadata": {
        "id": "0GQ1DAwqArzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gen_disc_loss(len(G_loss), G_loss, D_loss, \"Generator and Discriminator loss\")"
      ],
      "metadata": {
        "id": "7qjxoc-0zYQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(len(G_loss), G_loss, \"Generator GAN loss\", \"Gen GAN loss\")\n",
        "plot_loss(len(Total_gen_loss), Total_gen_loss, \"Generator GAN Loss + L1 loss\", \"Total gen loss\")\n",
        "plot_loss(len(G_loss), G_loss, \"Disciminator GAN loss\", \"Disc GAN loss\")"
      ],
      "metadata": {
        "id": "ARXjM8MaXWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gen_disc_loss(len(G_loss_val), G_loss_val, D_loss_val, \"Generator and Discriminator loss during validation\")"
      ],
      "metadata": {
        "id": "tLjsQ7j50HBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_val_loss(len(G_loss), G_loss, G_loss_val, 'Training and Validation Loss for Generator')"
      ],
      "metadata": {
        "id": "7nv8uMB6DJ6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_val_loss(len(D_loss), D_loss, D_loss_val, 'Training and Validation Loss for Discriminator')"
      ],
      "metadata": {
        "id": "GaR8Bm7CFyo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "gfOildcJabkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(gen, test_loader):\n",
        "  x, y = next(iter(test_loader))\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  # obtain original RGB image\n",
        "  real_imgs = labToRGB(x, y)\n",
        "  gen.eval()\n",
        "  with torch.no_grad():\n",
        "    y_fake = gen(x)\n",
        "    rgbImgs = labToRGB(x, y_fake)   # images to save\n",
        "\n",
        "  # Plot the images\n",
        "  bsize = test_loader.batch_size\n",
        "  fig = plt.figure(figsize=(15, 8))\n",
        "  for i in range(bsize):\n",
        "    ax = plt.subplot(3, bsize, i + 1)\n",
        "    ax.imshow(x[i][0].cpu(), cmap='gray')\n",
        "    ax.axis(\"off\")\n",
        "    ax = plt.subplot(3, bsize, i + 1 + bsize)\n",
        "    ax.imshow(rgbImgs[i])\n",
        "    ax.axis(\"off\")\n",
        "    ax = plt.subplot(3, bsize, i + 1 + bsize*2)\n",
        "    ax.imshow(real_imgs[i])\n",
        "    ax.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "  '''\n",
        "  TODO: Salvare le immagini\n",
        "  if save:\n",
        "    fig.savefig(f\"colorization_{time.time()}.png\")\n",
        "  '''\n",
        "  \n",
        "  gen.train()"
      ],
      "metadata": {
        "id": "FVJYvTDzlRNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation metrics"
      ],
      "metadata": {
        "id": "QYRgxWhu8xCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(gen, test_loader):\n",
        "  VGG16_sim_values = []\n",
        "  color_similarity = []\n",
        "  # TODO: altre metric\n",
        "  start = time.time()\n",
        "  for idx, (x, y) in enumerate(test_loader):\n",
        "    # Clear the output\n",
        "    #clear_output(wait=True)\n",
        "    print(\"Compting metrics for image: \", idx+1, \"/1000\")\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # obtain original RGB image\n",
        "    real_img = labToRGB(x, y)\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "      y_fake = gen(x)\n",
        "      # obtain generated img\n",
        "      rgb_fake = labToRGB(x, y_fake)\n",
        "    gen.train()\n",
        "    tmp = VGG16_similarity(real_img, rgb_fake)\n",
        "    VGG16_sim_values.append(tmp)\n",
        "    print(\"Test VGG16 similarity: \", tmp)\n",
        "    print(\"Test mse: \", mse_ab(y, y_fake))\n",
        "    #print(\"Test color distribution similarity TEST: \", ab_distribution_similarity(y, y_fake))\n",
        "    print(\"\\n\")\n",
        "  end = time.time()\n",
        "  print(\"Execution time:\", end - start)\n",
        "\n",
        "  print(\"Mean VGG16 cosine similarity: \", np.mean(VGG16_sim_values))\n"
      ],
      "metadata": {
        "id": "Th5Aklz837cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VGG16 Cosine similarity"
      ],
      "metadata": {
        "id": "qfCzlKvel3We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\t\t# Extract VGG-16 Feature Layers\n",
        "    self.features = list(model.features)\n",
        "    self.features = nn.Sequential(*self.features)\n",
        "\t\t# Extract VGG-16 Average Pooling Layer\n",
        "    self.pooling = model.avgpool\n",
        "\t\t# Convert the image into one-dimensional vector\n",
        "    self.flatten = nn.Flatten()\n",
        "\t\t# Extract the first part of fully-connected layer from VGG16\n",
        "    self.fc = model.classifier[0]\n",
        "  \n",
        "  def forward(self, x):\n",
        "\t\t# It will take the input 'x' until it returns the feature vector called 'out'\n",
        "    out = self.features(x)\n",
        "    out = self.pooling(out)\n",
        "    out = self.flatten(out)\n",
        "    out = self.fc(out) \n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "WY4unuO8ViBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(vector1, vector2):\n",
        "    # Compute the dot product between the vectors\n",
        "    dot_product = np.dot(vector1, vector2.T)\n",
        "    # Compute the Euclidean norms of the vectors\n",
        "    norm1 = np.linalg.norm(vector1)\n",
        "    norm2 = np.linalg.norm(vector2)\n",
        "    # Compute the cosine similarity\n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "def VGG16_similarity(realRGB, fakeRGB):\n",
        "  realRGB = realRGB.squeeze()\n",
        "  fakeRGB = fakeRGB.squeeze()\n",
        "  print(\"Start shape: \", realRGB.shape)\n",
        "  # Scale the image array from [0, 1] to [0, 255]\n",
        "  realRGB = (realRGB * 255).astype(np.uint8)\n",
        "  fakeRGB = (fakeRGB * 255).astype(np.uint8)\n",
        "  \n",
        "  # Create a figure with two subplots with the two images\n",
        "  fig, axes = plt.subplots(1, 2)\n",
        "  axes[0].imshow(realRGB)\n",
        "  axes[0].axis('off')\n",
        "  axes[1].imshow(fakeRGB)\n",
        "  axes[1].axis('off')\n",
        "  plt.subplots_adjust(wspace=0.1)\n",
        "  plt.show()\n",
        "  \n",
        "  # Initialize the model\n",
        "  model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "  new_model = FeatureExtractor(model)\n",
        "  # Change the device to GPU\n",
        "  new_model = new_model.to(device)\n",
        "\n",
        "  # Transform for the image, so it becomes readable with the model\n",
        "  transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.CenterCrop(512),\n",
        "    transforms.Resize(448),\n",
        "    transforms.ToTensor()                              \n",
        "  ])\n",
        "\n",
        "  realRGB = transform(realRGB)\n",
        "  fakeRGB = transform(fakeRGB)\n",
        "\t# Reshape the image. PyTorch model reads 4-dimensional tensor\n",
        "\t# [batch_size, channels, width, height]\n",
        "  realRGB = realRGB.reshape(1, 3, 448, 448)\n",
        "  fakeRGB = fakeRGB.reshape(1, 3, 448, 448)\n",
        "  realRGB = realRGB.to(device)\n",
        "  fakeRGB = fakeRGB.to(device)\n",
        "\t# We only extract features, so we don't need gradient\n",
        "  with torch.no_grad():\n",
        "\t\t# Extract the feature from the image\n",
        "    featureR = new_model(realRGB)\n",
        "    featureF = new_model(fakeRGB)\n",
        "\t# Convert to NumPy Array, Reshape it, and save it to features variable\n",
        "  features_real = featureR.cpu().detach().numpy().reshape(-1)\n",
        "  features_fake = featureF.cpu().detach().numpy().reshape(-1)\n",
        "\n",
        "  # Compute cosine similarity between the two vectors\n",
        "  return cosine_similarity(features_fake, features_real)\n",
        "\n"
      ],
      "metadata": {
        "id": "oSYcYDGslwb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MSE on ab "
      ],
      "metadata": {
        "id": "jZIpqecvBMjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_ab(real, fake):\n",
        "    real = real.cpu()\n",
        "    real = real.squeeze().permute(1, 2, 0).numpy()\n",
        "    fake = fake.cpu()\n",
        "    fake = fake.squeeze().permute(1, 2, 0).numpy()\n",
        "    # Flatten the vectors to 1D arrays\n",
        "    real_flat = real.flatten()\n",
        "    fake_flat = fake.flatten()\n",
        "    # Compute the mean squared error between the flattened vectors\n",
        "    return mean_squared_error(real_flat, fake_flat)"
      ],
      "metadata": {
        "id": "VDXXcvlVBX9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start testing"
      ],
      "metadata": {
        "id": "LU83ni62jVbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if TEST:\n",
        "  # Load the from the latest checkpoint on gdrive\n",
        "  print('--> TESTING <--')\n",
        "  gen = Generator(in_channels = 1)\n",
        "  gen.to(device)\n",
        "  opt_gen = optim.Adam(gen.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "  BCE = nn.BCEWithLogitsLoss()  # forse non serve\n",
        "  L1_LOSS = nn.L1Loss() # forse non serve\n",
        "\n",
        "  load_checkpoint(CHECKPOINT_GEN, gen, opt_gen, LR)\n",
        "  print('Generator model loaded.')\n",
        "\n",
        "  # Loading test set \n",
        "  test_dataset = image_coloring_dataset(paths=test_paths, split='test')\n",
        "  test_loader = DataLoader(test_dataset, batch_size=3, shuffle=True)\n",
        "  # Loader for compute the metrics (batch size = 1)\n",
        "  test_loader_metric = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "  print('Test set loaded.')"
      ],
      "metadata": {
        "id": "5v3oXFBDaffo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb480b32-07f1-456c-d251-f00b8100ea00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> TESTING <--\n",
            "Generator model loaded.\n",
            "Test set loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to see the generation of images.\n",
        "* 1st line --> BM images\n",
        "* 2nd line --> Gerated images\n",
        "* 3rd line --> Ground truth"
      ],
      "metadata": {
        "id": "lyRwJMzGb9J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if TEST:\n",
        "  #generate_images(gen, test_loader)\n",
        "  compute_metrics(gen, test_loader_metric)"
      ],
      "metadata": {
        "id": "PONqFSwhdOse"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}